{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from dotenv import dotenv_values\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', 10)  # or 1000\n",
    "pd.set_option('display.max_colwidth', None)  # or 199\n",
    "from data.preprocessing import DataPreprocessor\n",
    "from config import get_connection\n",
    "from data.db import execute_sql, batched_read_notification_sql\n",
    "from data.notifcation_preparation import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "conf = dotenv_values(\"../.env\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "conn = get_connection(conf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running batch id >= 0 and id < 1000\n"
     ]
    }
   ],
   "source": [
    "notifications = batched_read_notification_sql(conn, subset=15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(notifications)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "notifications_list = flat_notifications_from_sql(notifications)\n",
    "\n",
    "res = prepare_dataset(notifications_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res = DataPreprocessor.remove_partial_data(res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw = pd.DataFrame(data=res)\n",
    "df = raw.reindex(sorted(raw.columns), axis=1)\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = DataPreprocessor.remove_corrupt_data(df)\n",
    "df.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# remove semi missing data 2022-05-11 to 2022-05-24\n",
    "df = DataPreprocessor.remove_date_range(df,\n",
    "                                        datetime.fromisoformat(\"2022-05-11\"),\n",
    "                                        datetime.fromisoformat(\"2022-05-24\")\n",
    "                                        )\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# remove semi missing data 2022-06-30 16:30 to 2022-07-02 11:17\n",
    "df = DataPreprocessor.remove_date_range(df,\n",
    "                                        datetime.fromisoformat(\"2022-06-30 16:30\"),\n",
    "                                        datetime.fromisoformat(\"2022-07-02 11:17\")\n",
    "                                        )\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = DataPreprocessor.remove_most_recent_data(df)\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = DataPreprocessor.add_regression_label_columns(df)\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = DataPreprocessor.drop_categorical_features(df)\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#df.select_dtypes(include=['object'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(keep='first')\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# COMMENTED OUT\n",
    "# drop columns with duplicated values, leave first one\n",
    "#df = df.loc[:,~df.apply(lambda y: y.duplicated(),axis=1).all()].copy()\n",
    "#df.shape\n",
    "#df = DataPreprocessor.select_only_required_features(df)\n",
    "#df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "current_hourly_bars_closes = [col for col in df if col.startswith('current_hour_bars') and col.endswith('close')]\n",
    "\n",
    "current_hourly_bars_closes = sorted(current_hourly_bars_closes, reverse=True)\n",
    "current_hourly_bars_closes.append(\"latest_hour_close\")\n",
    "\n",
    "assert len(current_hourly_bars_closes) == 49\n",
    "assert current_hourly_bars_closes[-2] == 'current_hour_bars_01_close'\n",
    "\n",
    "len(current_hourly_bars_closes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "current_hourly_bars_highs = [col for col in df if col.startswith('current_hour_bars') and col.endswith('high')]\n",
    "\n",
    "current_hourly_bars_highs = sorted(current_hourly_bars_highs, reverse=True)\n",
    "current_hourly_bars_highs.append(\"latest_hour_close\")\n",
    "\n",
    "assert len(current_hourly_bars_highs) == 49\n",
    "assert current_hourly_bars_highs[-2] == 'current_hour_bars_01_high'\n",
    "\n",
    "len(current_hourly_bars_highs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "current_hourly_bars_lows = [col for col in df if col.startswith('current_hour_bars') and col.endswith('low')]\n",
    "\n",
    "current_hourly_bars_lows = sorted(current_hourly_bars_lows, reverse=True)\n",
    "current_hourly_bars_lows.append(\"latest_hour_close\")\n",
    "\n",
    "assert len(current_hourly_bars_lows) == 49\n",
    "assert current_hourly_bars_lows[-2] == 'current_hour_bars_01_low'\n",
    "\n",
    "len(current_hourly_bars_lows)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "higher_high_cols_shift_1 = DataPreprocessor.add_higher_high_col(df)\n",
    "df.loc[:, higher_high_cols_shift_1].tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "higher_high_cols_shift_5 = DataPreprocessor.add_higher_high_col(df, 5)\n",
    "df.loc[:, higher_high_cols_shift_5].tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "higher_high_cols_shift_10 = DataPreprocessor.add_higher_high_col(df, 10)\n",
    "df.loc[:, higher_high_cols_shift_10].tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "higher_high_cols_shift_20 = DataPreprocessor.add_higher_high_col(df, 20)\n",
    "df.loc[:, higher_high_cols_shift_20].tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "higher_high_cols_shift_40 = DataPreprocessor.add_higher_high_col(df, 40)\n",
    "df.loc[:, higher_high_cols_shift_40].tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check = higher_high_cols_shift_1 + ['latest_hour_close', 'current_hour_bars_01_close']\n",
    "df.loc[:, check].tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#checks that all cols are not empty even if underlying data is nan\n",
    "df.loc[:, check].loc[df['current_hour_bars_01_close'].isna()].tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "current_hourly_bars_closes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# manual EMA calculation\n",
    "# df['EMA_HOUR_25'] = df.loc[:, current_hourly_bars_closes].ewm(span=25, ignore_na=True, axis=1).mean()['latest_hour_close']\n",
    "# df['EMA_HOUR_49'] = df.loc[:, current_hourly_bars_closes].ewm(span=49, ignore_na=True, axis=1).mean()['latest_hour_close']\n",
    "# ewm25\n",
    "# df.loc[:,['EMA_HOUR_25', 'EMA_HOUR_49', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas_ta as pta\n",
    "def pta_ema(row): \n",
    "  return pta.ema(row, length = 25)\n",
    "ema = df[current_hourly_bars_closes].apply(pta_ema, axis=1, result_type='expand')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import ta\n",
    "from ta.trend import ema_indicator\n",
    "def ta_ema(row): \n",
    "  return ema_indicator(row, window = 25)\n",
    "ema_ta = df[current_hourly_bars_closes].apply(ta_ema, axis=1, result_type='expand')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from indicators.momentum import willr\n",
    "from functools import partial\n",
    "df.apply(\n",
    "    partial(willr, high_cols=current_hourly_bars_highs, low_cols=current_hourly_bars_lows, close_cols=current_hourly_bars_closes), \n",
    "    axis=1, \n",
    "    result_type='expand'\n",
    ").tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from indicators.core import add_indicator_to_df\n",
    "import indicators.trend as it\n",
    "import indicators.momentum as im"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = add_indicator_to_df(base_df=df,\n",
    "                    subset_df=df[current_hourly_bars_closes],\n",
    "                    func=partial(it.ema, length=20),\n",
    "                    prefix=\"EMA_20_MINUS\",\n",
    "                    postfix=\"HOUR\",\n",
    "                    number_of_cols_to_add=10)\n",
    "df = add_indicator_to_df(base_df=df,\n",
    "                    subset_df=df[current_hourly_bars_closes],\n",
    "                    func=partial(it.ema, length=40),\n",
    "                    prefix=\"EMA_40_MINUS\",\n",
    "                    postfix=\"HOUR\",\n",
    "                    number_of_cols_to_add=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = add_indicator_to_df(base_df=df,\n",
    "                    subset_df=df[current_hourly_bars_closes],\n",
    "                    func=partial(it.dema, length=30),\n",
    "                    prefix=\"DEMA_30_MINUS\",\n",
    "                    postfix=\"HOUR\",\n",
    "                    number_of_cols_to_add=5)\n",
    "df = add_indicator_to_df(base_df=df,\n",
    "                    subset_df=df[current_hourly_bars_closes],\n",
    "                    func=partial(it.dema, length=15),\n",
    "                    prefix=\"DEMA_15_MINUS\",\n",
    "                    postfix=\"HOUR\",\n",
    "                    number_of_cols_to_add=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = add_indicator_to_df(base_df=df,\n",
    "                    subset_df=df[current_hourly_bars_closes],\n",
    "                    func=partial(im.rsi, length=30),\n",
    "                    prefix=\"RSI_30_MINUS\",\n",
    "                    postfix=\"HOUR\",\n",
    "                    number_of_cols_to_add=5)\n",
    "df = add_indicator_to_df(base_df=df,\n",
    "                    subset_df=df[current_hourly_bars_closes],\n",
    "                    func=partial(im.rsi, length=15),\n",
    "                    prefix=\"RSI_15_MINUS\",\n",
    "                    postfix=\"HOUR\",\n",
    "                    number_of_cols_to_add=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = add_indicator_to_df(base_df=df,\n",
    "                    subset_df=df[current_hourly_bars_closes],\n",
    "                    func=partial(im.rapo),\n",
    "                    prefix=\"RAPO_MINUS\",\n",
    "                    postfix=\"HOUR\",\n",
    "                    number_of_cols_to_add=10)\n",
    "# df = add_indicator_to_df(base_df=df,\n",
    "#                     subset_df=df[current_hourly_bars_closes],\n",
    "#                     func=partial(im.rapo, length=15),\n",
    "#                     prefix=\"RAPO_15_MINUS\",\n",
    "#                     postfix=\"HOUR\",\n",
    "#                     number_of_cols_to_add=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df= add_indicator_to_df(base_df=df,\n",
    "                    subset_df=df[current_hourly_bars_highs + current_hourly_bars_lows + current_hourly_bars_closes],\n",
    "                    func=partial(im.willr, length=30, high_cols=current_hourly_bars_highs, low_cols=current_hourly_bars_lows, close_cols=current_hourly_bars_closes),\n",
    "                    prefix=\"WILLR_30_MINUS\",\n",
    "                    postfix=\"HOUR\",\n",
    "                    number_of_cols_to_add=5)\n",
    "df = add_indicator_to_df(base_df=df,\n",
    "                    subset_df=df[current_hourly_bars_highs + current_hourly_bars_lows + current_hourly_bars_closes],\n",
    "                    func=partial(im.willr, length=15, high_cols=current_hourly_bars_highs, low_cols=current_hourly_bars_lows, close_cols=current_hourly_bars_closes),\n",
    "                    prefix=\"WILLR_15_MINUS\",\n",
    "                    postfix=\"HOUR\",\n",
    "                    number_of_cols_to_add=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ema_ta.iloc[:, -10:].columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = DataPreprocessor.drop_minutely_bar_cols(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = DataPreprocessor.drop_hourly_bar_ohl_cols(df)\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = DataPreprocessor.drop_btc_stats_map_ol_cols(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = DataPreprocessor.drop_history_stats_map_ohl_cols(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = DataPreprocessor.drop_highly_correlated_features(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = DataPreprocessor.drop_highly_missing_features(df)\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "corr_matrix = df.corr().abs()\n",
    "\n",
    "#the matrix is symmetric so we need to extract upper triangle matrix without diagonal (k = 1)\n",
    "\n",
    "sol = (corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "                  .stack()\n",
    "                  .sort_values(ascending=False))\n",
    "\n",
    "#first element of sol series is the pair with the biggest correlation\n",
    "check_cols = set()\n",
    "for index, value in sol.items():\n",
    "    # do some staff\n",
    "    if value > 0.9:\n",
    "        #print(index, value)\n",
    "        for v in index:\n",
    "            check_cols.add(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "check_cols = sorted(check_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "check_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.loc[:, check_cols].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((df.isnull() | df.isna()).sum() * 100 / df.index.size).round(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "sns.heatmap(df.isnull(),cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Initial try, with filling df with 0\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# if volume is negative - replace with zero\n",
    "DataPreprocessor.replace_negative_volumes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#already added as 'latest_hour_volume'\n",
    "#DataPreprocessor.add_current_hour_volume(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "history_vol_cols = DataPreprocessor.add_current_hour_volume_to_historical_volumes_coef(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "next(history_vol_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# finding corrupt data with excessive volumes, requires categorical features\n",
    "#df[(df[\"id\"] > 13000) & (df[\"id\"] < 17000)].loc[::, [\"id\", \"notification_date\", *next(history_vol_cols)]].nlargest(n=3000, columns=['current_h_vol_to_28_days_avg'], keep='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Which signal made best return?\n",
    "df[df['LABEL_UP_RETURN'] == df['LABEL_UP_RETURN'].max()].loc[:, ['price', 'LABEL_UP_RETURN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Which signal made worst return?\n",
    "df[df['LABEL_DOWN_RETURN'] == df['LABEL_DOWN_RETURN'].min()].loc[:, ['price', 'LABEL_DOWN_RETURN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_vol = df[[*next(history_vol_cols), 'LABEL_UP_RETURN', 'LABEL_DOWN_RETURN']]\n",
    "x = df_vol.drop(['LABEL_UP_RETURN','LABEL_DOWN_RETURN'], 1)\n",
    "\n",
    "# cleaning outliers in data\n",
    "df_vol_coef_clean = df_vol[((x > x.quantile(.03)) & (x < x.quantile(.97))).all(1)]\n",
    "#df_vol_coef_clean = df_vol[(np.abs(stats.zscore(df_vol)) < 4).all(axis=1)]\n",
    "df_vol_coef_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df_vol_coef_clean.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = next(DataPreprocessor.remove_outliers(df, history_vol_cols))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# removing those which don't have -3 hours of data\n",
    "df = DataPreprocessor.remove_rows_with_less_than_3_hours(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_change_since_previous = next(DataPreprocessor.add_change_since_1_2_3_hours_back(df))\n",
    "sns.heatmap(df_change_since_previous.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# there is some reverse correlation in change and down return\n",
    "sns.scatterplot(df['CHANGE_SINCE_01_HOUR_BARS'], df['LABEL_DOWN_RETURN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_volume_on_previous = df[['current_hour_bars_01_volume',\n",
    "    'current_hour_bars_02_volume',\n",
    "    'current_hour_bars_03_volume',\n",
    "    'LABEL_UP_RETURN', 'LABEL_DOWN_RETURN']]\n",
    "sns.heatmap(df_volume_on_previous.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "DataPreprocessor.add_1_2_3_h_bars_vol_to_history_vol_coef(df)\n",
    "df_volume_on_previous_as_coef = df[['_01_H_BARS_VOL_TO_28D_AVG_H_VOL',\n",
    "    '_02_H_BARS_VOL_TO_28D_AVG_H_VOL',\n",
    "    '_03_H_BARS_VOL_TO_28D_AVG_H_VOL',\n",
    "    'LABEL_UP_RETURN', 'LABEL_DOWN_RETURN']]\n",
    "sns.heatmap(df_volume_on_previous_as_coef.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "history_change_rate_cols = [c for c in df.columns if str(c).startswith('history_statsMap_-') and str(c).endswith('changeRate')]\n",
    "df_history_change_rate = df[[*history_change_rate_cols, 'LABEL_UP_RETURN', 'LABEL_DOWN_RETURN']]\n",
    "sns.heatmap(df_history_change_rate.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_vol_coef_clean[df_vol_coef_clean['CURRENT_H_VOL_TO_5_DAYS_AVG'] == df_vol_coef_clean['CURRENT_H_VOL_TO_5_DAYS_AVG'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with_cat = df\n",
    "with_cat['up_return'] = pd.cut(df['LABEL_UP_RETURN'],\n",
    "                               bins=[0, 30, 40, 50, 70, 100, 300, float('Inf')], \n",
    "                               labels=['0-30', '30-40', '40-50', '50-70', '70-100', '100-300', '300+'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with_cat['down_return'] = pd.cut(df['LABEL_DOWN_RETURN'],\n",
    "                                 bins=[float('-Inf'), -30, -20, -10, 0], \n",
    "                                 labels=['-30', '-30-20', '-20-10', '-10-0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.displot(df_vol_coef_clean, x='current_h_vol_to_5_days_avg', bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'up_return', y = 'current_hour_bars_01_volume', data = with_cat, showfliers = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'up_return', y = 'current_hour_bars_02_volume', data = with_cat, showfliers = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'up_return', y = 'current_hour_bars_03_volume', data = with_cat, showfliers = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'up_return', y = 'change_since_01_hour_bars', data = with_cat, showfliers = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'up_return', y = 'change_since_02_hour_bars', data = with_cat, showfliers = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'up_return', y = 'change_since_03_hour_bars', data = with_cat, showfliers = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'down_return', y = 'change_since_01_hour_bars', data = with_cat, showfliers = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'down_return', y = 'change_since_02_hour_bars', data = with_cat, showfliers = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'down_return', y = 'change_since_03_hour_bars', data = with_cat, showfliers = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'up_return', y = 'current_h_vol_to_5_days_avg', data = with_cat, showfliers = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'up_return', y = 'current_h_vol_to_14_days_avg', data = with_cat, showfliers = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'up_return', y = 'current_h_vol_to_28_days_avg', data = with_cat, showfliers = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'down_return', y = 'current_h_vol_to_5_days_avg', data = with_cat, showfliers = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'down_return', y = 'current_h_vol_to_28_days_avg', data = with_cat, showfliers = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_vol_coef_clean.nlargest(n=20, columns=['current_h_vol_to_5_days_avg'], keep='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 10 largest by up return\n",
    "df_vol_coef_clean.nlargest(n=20, columns=['label_up_return'], keep='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 10 smallest by down return\n",
    "df_vol_coef_clean.nsmallest(n=20, columns=['label_down_return'], keep='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# for c in  history_vol_cols:\n",
    "#     sns.displot(df_vol_coef_clean[c], stat = 'density', binwidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from data.scalers import min_max_scaler, standard_scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(['up_return', 'down_return'], axis=1)\n",
    "df_norm = min_max_scaler(df)\n",
    "df_std= standard_scaler(df)\n",
    "##%%\n",
    "#corr = df.corr()['label_up_return']\n",
    "##%%\n",
    "#pd.set_option('display.max_rows', None)  # or 1000\n",
    "#abs(corr).sort_values(ascending=False)\n",
    "##%%\n",
    "#pd.set_option('display.max_rows', 10)  # or 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "label_cols = ['label_up_return', 'label_down_return']\n",
    "x = df.drop(label_cols, axis=1)\n",
    "y_up = df['label_up_return']\n",
    "y_down = df['label_down_return']\n",
    "\n",
    "x_norm = df_norm.drop(label_cols, axis=1)\n",
    "y_up_norm = df_norm['label_up_return']\n",
    "y_down_norm = df_norm['label_down_return']\n",
    "\n",
    "x_std = df_std.drop(label_cols, axis=1)\n",
    "y_up_std = df_std['label_up_return']\n",
    "y_down_std = df_std['label_down_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# EDA using SWEETVIZ automl library\n",
    "#import sweetviz as sv\n",
    "#sv_report = sv.analyze(df, pairwise_analysis='off')\n",
    "#sv_report.show_html(\"sv.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from model_factory import ModelFactory\n",
    "_, y_up_class = ModelFactory.prepare_classification_label(df, 20)\n",
    "y_up_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "_, y_down_class = ModelFactory.prepare_classification_label(df, -10)\n",
    "y_down_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def train_random_forest_clasifier(x, y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "    rfc = ExtraTreesClassifier()\n",
    "    rfc.fit(x_train, y_train)\n",
    "    return x_train, x_test, y_train, y_test, rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def train_logistic_regression_clasifier(x, y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    rfc = LogisticRegression(max_iter=5000, penalty=\"l2\")\n",
    "    rfc.fit(x_train, y_train)\n",
    "    return x_train, x_test, y_train, y_test, rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x_up_class, x_up_test_class, y_train_up_class, y_up_test_class, up_random_forest_model = train_random_forest_clasifier(x, y_up_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def eval_model(x_up_class, x_up_test_class, y_up_class, y_up_test_class, up_random_forest_model):\n",
    "    # Make predictions for the test UP set\n",
    "    y_up_predictions = up_random_forest_model.predict(x_up_test_class)\n",
    "    # View accuracy score\n",
    "    print(accuracy_score(y_up_test_class, y_up_predictions))\n",
    "    \n",
    "    # View confusion matrix for test data and predictions\n",
    "    matrix = confusion_matrix(y_up_test_class, y_up_predictions)\n",
    "    print(matrix)\n",
    "    matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Build the plot\n",
    "    plt.figure(figsize=(16,7))\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "                cmap=plt.cm.Greens, linewidths=0.2)\n",
    "    \n",
    "    # Add labels to the plot\n",
    "    class_names = ['Higher than 20%', 'Lower Than 20%']\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    tick_marks2 = tick_marks + 0.5\n",
    "    plt.xticks(tick_marks, class_names, rotation=25)\n",
    "    plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.title('Confusion Matrix for Random Forest Model')\n",
    "    plt.show()\n",
    "    # View the classification report for test data and predictions\n",
    "    print(classification_report(y_up_test_class, y_up_predictions))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "eval_model(x_up_class, x_up_test_class, y_train_up_class, y_up_test_class, up_random_forest_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import os \n",
    "from sklearn import tree\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=800)\n",
    "tree.plot_tree(up_random_forest_model.estimators_[0],\n",
    "feature_names=x_up_class.columns,\n",
    "class_names=y_train_up_class.columns,\n",
    "filled=True,\n",
    "rounded=True)\n",
    "fig.savefig('rf_individualtree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "importances = up_random_forest_model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in up_random_forest_model.estimators_], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "forest_importances = pd.Series(importances, index=x_up_class.columns)\n",
    "forest_importances.nlargest(30).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 50)  # or 1000\n",
    "\n",
    "forest_importances.nlargest(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "eval_model(*train_logistic_regression_clasifier(x_std, y_up_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x_down_class, x_down_test_class, y_down_train_class, y_down_test_class, down_random_forest_model = train_random_forest_clasifier(x, y_down_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions for the test DOWN set\n",
    "y_down_predictions = down_random_forest_model.predict(x_down_test_class)\n",
    "# View accuracy score\n",
    "accuracy_score(y_down_test_class, y_down_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# View confusion matrix for test data and predictions\n",
    "matrix = confusion_matrix(y_down_test_class, y_down_predictions)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = ['Lower than -10%', 'Higher Than -10%']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Random Forest Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "forest_importances = pd.Series(down_random_forest_model.feature_importances_, index=x_down_class.columns)\n",
    "forest_importances.nlargest(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# View the classification report for test data and predictions\n",
    "print(classification_report(y_down_test_class, y_down_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# check stats using OLS from statsmodels\n",
    "#import statsmodels.api as sm\n",
    "#results = sm.OLS(y_up,x).fit()\n",
    "#results.summary()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (trading-bot-ml)",
   "language": "python",
   "name": "pycharm-1c3c67ad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}